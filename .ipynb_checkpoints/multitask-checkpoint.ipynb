{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kCeYA79m1DEX"
   },
   "source": [
    "# Multi-task Movie Recommenders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZwrcZeK7x7xI"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T12:11:37.778960Z",
     "iopub.status.busy": "2021-11-30T12:11:37.778338Z",
     "iopub.status.idle": "2021-11-30T12:11:40.114775Z",
     "shell.execute_reply": "2021-11-30T12:11:40.115239Z"
    },
    "id": "SZGYDaF-m5wZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile\n",
    "\n",
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5PAqjR4a1RR4"
   },
   "source": [
    "## Preparing the dataset\n",
    "\n",
    "We're going to use the Movielens 100K dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Toy Story (1995)\"</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>\"Jumanji (1995)\"</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>\"Grumpier Old Men (1995)\"</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>\"Waiting to Exhale (1995)\"</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>\"Father of the Bride Part II (1995)\"</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>\"Heat (1995)\"</td>\n",
       "      <td>Action|Crime|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>\"Sabrina (1995)\"</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>\"Tom and Huck (1995)\"</td>\n",
       "      <td>Adventure|Children</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>\"Sudden Death (1995)\"</td>\n",
       "      <td>Action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>\"GoldenEye (1995)\"</td>\n",
       "      <td>Action|Adventure|Thriller</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                                 title  \\\n",
       "0        1                    \"Toy Story (1995)\"   \n",
       "1        2                      \"Jumanji (1995)\"   \n",
       "2        3             \"Grumpier Old Men (1995)\"   \n",
       "3        4            \"Waiting to Exhale (1995)\"   \n",
       "4        5  \"Father of the Bride Part II (1995)\"   \n",
       "5        6                         \"Heat (1995)\"   \n",
       "6        7                      \"Sabrina (1995)\"   \n",
       "7        8                 \"Tom and Huck (1995)\"   \n",
       "8        9                 \"Sudden Death (1995)\"   \n",
       "9       10                    \"GoldenEye (1995)\"   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  \n",
       "5                        Action|Crime|Thriller  \n",
       "6                               Comedy|Romance  \n",
       "7                           Adventure|Children  \n",
       "8                                       Action  \n",
       "9                    Action|Adventure|Thriller  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "import json \n",
    "df_movies=pd.read_csv(\"./assets/ml-latest-small/movies.csv\")\n",
    "df_movies[\"title\"]=df_movies[\"title\"].apply(lambda x: json.dumps(x))\n",
    "# df_movies.isnull().sum()\n",
    "# df_movies.drop(df_movies[df_movies[\"title\"]==\"'71 (2014)\"].index,axis=0,inplace=True)\n",
    "# df_movies[df_movies[\"title\"]==\"\"71 (2014)\"]\n",
    "# # df_movies.dtypes\n",
    "df_movies.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>3.0</td>\n",
       "      <td>964982400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964980868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964984041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964984100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931\n",
       "5       1       70     3.0  964982400\n",
       "6       1      101     5.0  964980868\n",
       "7       1      110     4.0  964982176\n",
       "8       1      151     5.0  964984041\n",
       "9       1      157     5.0  964984100"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings=pd.read_csv(\"./assets/ml-latest-small/ratings.csv\")\n",
    "df_ratings.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_movies contains a column named \"id\" which is different from the column \"movieId\" in df_rating. However, we have a third dataset that links between these two ids. We need to join some datasets to prepare our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>tag</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>60756</td>\n",
       "      <td>funny</td>\n",
       "      <td>1445714994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>60756</td>\n",
       "      <td>Highly quotable</td>\n",
       "      <td>1445714996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>60756</td>\n",
       "      <td>will ferrell</td>\n",
       "      <td>1445714992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>89774</td>\n",
       "      <td>Boxing story</td>\n",
       "      <td>1445715207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>89774</td>\n",
       "      <td>MMA</td>\n",
       "      <td>1445715200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>89774</td>\n",
       "      <td>Tom Hardy</td>\n",
       "      <td>1445715205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>106782</td>\n",
       "      <td>drugs</td>\n",
       "      <td>1445715054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>106782</td>\n",
       "      <td>Leonardo DiCaprio</td>\n",
       "      <td>1445715051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>106782</td>\n",
       "      <td>Martin Scorsese</td>\n",
       "      <td>1445715056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>48516</td>\n",
       "      <td>way too long</td>\n",
       "      <td>1169687325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId                tag   timestamp\n",
       "0       2    60756              funny  1445714994\n",
       "1       2    60756    Highly quotable  1445714996\n",
       "2       2    60756       will ferrell  1445714992\n",
       "3       2    89774       Boxing story  1445715207\n",
       "4       2    89774                MMA  1445715200\n",
       "5       2    89774          Tom Hardy  1445715205\n",
       "6       2   106782              drugs  1445715054\n",
       "7       2   106782  Leonardo DiCaprio  1445715051\n",
       "8       2   106782    Martin Scorsese  1445715056\n",
       "9       7    48516       way too long  1169687325"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tags=pd.read_csv(\"./assets/ml-latest-small/tags.csv\")\n",
    "df_tags.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100816</th>\n",
       "      <td>610</td>\n",
       "      <td>158872</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1493848024</td>\n",
       "      <td>\"Sausage Party (2016)\"</td>\n",
       "      <td>Animation|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100817</th>\n",
       "      <td>610</td>\n",
       "      <td>158956</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1493848947</td>\n",
       "      <td>\"Kill Command (2016)\"</td>\n",
       "      <td>Action|Horror|Sci-Fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100818</th>\n",
       "      <td>610</td>\n",
       "      <td>159093</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1493847704</td>\n",
       "      <td>\"Now You See Me 2 (2016)\"</td>\n",
       "      <td>Action|Comedy|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100819</th>\n",
       "      <td>610</td>\n",
       "      <td>160080</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1493848031</td>\n",
       "      <td>\"Ghostbusters (2016)\"</td>\n",
       "      <td>Action|Comedy|Horror|Sci-Fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100820</th>\n",
       "      <td>610</td>\n",
       "      <td>160341</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1479545749</td>\n",
       "      <td>\"Bloodmoon (1997)\"</td>\n",
       "      <td>Action|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100821</th>\n",
       "      <td>610</td>\n",
       "      <td>160527</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1479544998</td>\n",
       "      <td>\"Sympathy for the Underdog (1971)\"</td>\n",
       "      <td>Action|Crime|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100822</th>\n",
       "      <td>610</td>\n",
       "      <td>160571</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1493848537</td>\n",
       "      <td>\"Lights Out (2016)\"</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100823</th>\n",
       "      <td>610</td>\n",
       "      <td>160836</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1493844794</td>\n",
       "      <td>\"Hazard (2005)\"</td>\n",
       "      <td>Action|Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100824</th>\n",
       "      <td>610</td>\n",
       "      <td>161582</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1493847759</td>\n",
       "      <td>\"Hell or High Water (2016)\"</td>\n",
       "      <td>Crime|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100825</th>\n",
       "      <td>610</td>\n",
       "      <td>161634</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1493848362</td>\n",
       "      <td>\"Don't Breathe (2016)\"</td>\n",
       "      <td>Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100826</th>\n",
       "      <td>610</td>\n",
       "      <td>162350</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1493849971</td>\n",
       "      <td>\"The Magnificent Seven (2016)\"</td>\n",
       "      <td>Action|Western</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100827</th>\n",
       "      <td>610</td>\n",
       "      <td>163937</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1493848789</td>\n",
       "      <td>\"Blair Witch (2016)\"</td>\n",
       "      <td>Horror|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100828</th>\n",
       "      <td>610</td>\n",
       "      <td>163981</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1493850155</td>\n",
       "      <td>\"31 (2016)\"</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100829</th>\n",
       "      <td>610</td>\n",
       "      <td>164179</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1493845631</td>\n",
       "      <td>\"Arrival (2016)\"</td>\n",
       "      <td>Sci-Fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100830</th>\n",
       "      <td>610</td>\n",
       "      <td>166528</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1493879365</td>\n",
       "      <td>\"Rogue One: A Star Wars Story (2016)\"</td>\n",
       "      <td>Action|Adventure|Fantasy|Sci-Fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100831</th>\n",
       "      <td>610</td>\n",
       "      <td>166534</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1493848402</td>\n",
       "      <td>\"Split (2017)\"</td>\n",
       "      <td>Drama|Horror|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100832</th>\n",
       "      <td>610</td>\n",
       "      <td>168248</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1493850091</td>\n",
       "      <td>\"John Wick: Chapter Two (2017)\"</td>\n",
       "      <td>Action|Crime|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100833</th>\n",
       "      <td>610</td>\n",
       "      <td>168250</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1494273047</td>\n",
       "      <td>\"Get Out (2017)\"</td>\n",
       "      <td>Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100834</th>\n",
       "      <td>610</td>\n",
       "      <td>168252</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1493846352</td>\n",
       "      <td>\"Logan (2017)\"</td>\n",
       "      <td>Action|Sci-Fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100835</th>\n",
       "      <td>610</td>\n",
       "      <td>170875</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1493846415</td>\n",
       "      <td>\"The Fate of the Furious (2017)\"</td>\n",
       "      <td>Action|Crime|Drama|Thriller</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating   timestamp  \\\n",
       "100816     610   158872     3.5  1493848024   \n",
       "100817     610   158956     3.0  1493848947   \n",
       "100818     610   159093     3.0  1493847704   \n",
       "100819     610   160080     3.0  1493848031   \n",
       "100820     610   160341     2.5  1479545749   \n",
       "100821     610   160527     4.5  1479544998   \n",
       "100822     610   160571     3.0  1493848537   \n",
       "100823     610   160836     3.0  1493844794   \n",
       "100824     610   161582     4.0  1493847759   \n",
       "100825     610   161634     4.0  1493848362   \n",
       "100826     610   162350     3.5  1493849971   \n",
       "100827     610   163937     3.5  1493848789   \n",
       "100828     610   163981     3.5  1493850155   \n",
       "100829     610   164179     5.0  1493845631   \n",
       "100830     610   166528     4.0  1493879365   \n",
       "100831     610   166534     4.0  1493848402   \n",
       "100832     610   168248     5.0  1493850091   \n",
       "100833     610   168250     5.0  1494273047   \n",
       "100834     610   168252     5.0  1493846352   \n",
       "100835     610   170875     3.0  1493846415   \n",
       "\n",
       "                                        title                           genres  \n",
       "100816                 \"Sausage Party (2016)\"                 Animation|Comedy  \n",
       "100817                  \"Kill Command (2016)\"             Action|Horror|Sci-Fi  \n",
       "100818              \"Now You See Me 2 (2016)\"           Action|Comedy|Thriller  \n",
       "100819                  \"Ghostbusters (2016)\"      Action|Comedy|Horror|Sci-Fi  \n",
       "100820                     \"Bloodmoon (1997)\"                  Action|Thriller  \n",
       "100821     \"Sympathy for the Underdog (1971)\"               Action|Crime|Drama  \n",
       "100822                    \"Lights Out (2016)\"                           Horror  \n",
       "100823                        \"Hazard (2005)\"            Action|Drama|Thriller  \n",
       "100824            \"Hell or High Water (2016)\"                      Crime|Drama  \n",
       "100825                 \"Don't Breathe (2016)\"                         Thriller  \n",
       "100826         \"The Magnificent Seven (2016)\"                   Action|Western  \n",
       "100827                   \"Blair Witch (2016)\"                  Horror|Thriller  \n",
       "100828                            \"31 (2016)\"                           Horror  \n",
       "100829                       \"Arrival (2016)\"                           Sci-Fi  \n",
       "100830  \"Rogue One: A Star Wars Story (2016)\"  Action|Adventure|Fantasy|Sci-Fi  \n",
       "100831                         \"Split (2017)\"            Drama|Horror|Thriller  \n",
       "100832        \"John Wick: Chapter Two (2017)\"            Action|Crime|Thriller  \n",
       "100833                       \"Get Out (2017)\"                           Horror  \n",
       "100834                         \"Logan (2017)\"                    Action|Sci-Fi  \n",
       "100835       \"The Fate of the Furious (2017)\"      Action|Crime|Drama|Thriller  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings=df_ratings.join(df_movies.set_index('movieId'), on='movieId')\n",
    "df_ratings.tail(20)\n",
    "df_ratings.isnull().sum()\n",
    "df_ratings.dropna(subset=[\"title\"],inplace=True)\n",
    "df_ratings.isnull().sum()\n",
    "# df_ratings.shape\n",
    "df_ratings.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=df_movies[[\"_id\",\"title\"]]\n",
    "# df=df.join(df_links.set_index(\"tmdbId\"), on=\"id\")\n",
    "# df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T12:11:40.135684Z",
     "iopub.status.busy": "2021-11-30T12:11:40.135058Z",
     "iopub.status.idle": "2021-11-30T12:11:50.191175Z",
     "shell.execute_reply": "2021-11-30T12:11:50.190557Z"
    },
    "id": "-ySWtibjm_6a"
   },
   "outputs": [],
   "source": [
    "slices_rating=tf.data.Dataset.from_tensor_slices(dict(df_ratings[[\"rating\",\"userId\",\"title\"]]))\n",
    "slices_movies=tf.data.Dataset.from_tensor_slices(dict(df_movies[[\"movieId\",\"title\"]]))\n",
    "\n",
    "# Select the basic features.\n",
    "ratings = slices_rating.map(lambda x: {\n",
    "    \"title\": x[\"title\"],\n",
    "    \"userId\": x[\"userId\"],\n",
    "    \"rating\": x[\"rating\"],\n",
    "})\n",
    "movies = slices_movies.map(lambda x: x[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T12:11:50.198585Z",
     "iopub.status.busy": "2021-11-30T12:11:50.197900Z",
     "iopub.status.idle": "2021-11-30T12:11:58.664631Z",
     "shell.execute_reply": "2021-11-30T12:11:58.665082Z"
    },
    "id": "rS0eDfkjnjJL"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)\n",
    "\n",
    "movie_titles = movies.batch(1_000)\n",
    "user_ids = ratings.batch(10_000).map(lambda x: x[\"userId\"])\n",
    "\n",
    "unique_movie_titles = np.unique(np.concatenate(list(movie_titles)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWCwkE5z8QBe"
   },
   "source": [
    "The recommender will have two tasks. The first is the rating task:\n",
    "\n",
    "```python\n",
    "tfrs.tasks.Ranking(\n",
    "    loss=tf.keras.losses.MeanSquaredError(),\n",
    "    metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrgQIXEm8UWf"
   },
   "source": [
    "Its goal is to predict the ratings as accurately as possible.\n",
    "\n",
    "The second is the retrieval task:\n",
    "\n",
    "```python\n",
    "tfrs.tasks.Retrieval(\n",
    "    metrics=tfrs.metrics.FactorizedTopK(\n",
    "        candidates=movies.batch(128)\n",
    "    )\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SCNrv7_gakmF"
   },
   "source": [
    "This task's goal is to predict which movies the user will or will not watch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T12:11:58.679063Z",
     "iopub.status.busy": "2021-11-30T12:11:58.677922Z",
     "iopub.status.idle": "2021-11-30T12:11:58.679967Z",
     "shell.execute_reply": "2021-11-30T12:11:58.680339Z"
    },
    "id": "YFSkOAMgzU0K"
   },
   "outputs": [],
   "source": [
    "class MyModel(tfrs.models.Model):\n",
    "\n",
    "    def __init__(self, rating_weight: float, retrieval_weight: float) -> None:\n",
    "        # We take the loss weights in the constructor: this allows us to instantiate\n",
    "        # several model objects with different loss weights.\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        embedding_dimension = 32\n",
    "\n",
    "        # User and movie models.\n",
    "        self.movie_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "          tf.keras.layers.StringLookup(\n",
    "            vocabulary=unique_movie_titles, mask_token=None),\n",
    "          tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "        ])\n",
    "        self.user_model: tf.keras.layers.Layer = tf.keras.Sequential([\n",
    "          tf.keras.layers.IntegerLookup(\n",
    "            vocabulary=unique_user_ids, mask_token=None),\n",
    "          tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        # A small model to take in user and movie embeddings and predict ratings.\n",
    "        # We can make this as complicated as we want as long as we output a scalar\n",
    "        # as our prediction.\n",
    "        self.rating_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(1),\n",
    "        ])\n",
    "\n",
    "        # The tasks.\n",
    "        self.rating_task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "            loss=tf.keras.losses.MeanSquaredError(),\n",
    "            metrics=[tf.keras.metrics.RootMeanSquaredError()],\n",
    "        )\n",
    "        self.retrieval_task: tf.keras.layers.Layer = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates=movies.batch(128).map(self.movie_model)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # The loss weights.\n",
    "        self.rating_weight = rating_weight\n",
    "        self.retrieval_weight = retrieval_weight\n",
    "\n",
    "    def call(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:\n",
    "        # We pick out the user features and pass them into the user model.\n",
    "        user_embeddings = self.user_model(features[\"userId\"])\n",
    "        # And pick out the movie features and pass them into the movie model.\n",
    "        movie_embeddings = self.movie_model(features[\"title\"])\n",
    "\n",
    "        return (\n",
    "            user_embeddings,\n",
    "            movie_embeddings,\n",
    "            # We apply the multi-layered rating model to a concatentation of\n",
    "            # user and movie embeddings.\n",
    "            self.rating_model(\n",
    "                tf.concat([user_embeddings, movie_embeddings], axis=1)\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "\n",
    "        ratings = features.pop(\"rating\")\n",
    "\n",
    "        user_embeddings, movie_embeddings, rating_predictions = self(features)\n",
    "\n",
    "        # We compute the loss for each task.\n",
    "        rating_loss = self.rating_task(\n",
    "            labels=ratings,\n",
    "            predictions=rating_predictions,\n",
    "        )\n",
    "        retrieval_loss = self.retrieval_task(user_embeddings, movie_embeddings)\n",
    "\n",
    "        # And combine them using the loss weights.\n",
    "        return (self.rating_weight * rating_loss\n",
    "                + self.retrieval_weight * retrieval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankingModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        embedding_dimension = 32\n",
    "\n",
    "        # Compute embeddings for users.\n",
    "        self.user_embeddings = tf.keras.Sequential([\n",
    "          tf.keras.layers.IntegerLookup(\n",
    "            vocabulary=unique_user_ids, mask_token=None),\n",
    "          tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        # Compute embeddings for movies.\n",
    "        self.movie_embeddings = tf.keras.Sequential([\n",
    "          tf.keras.layers.StringLookup(\n",
    "            vocabulary=unique_movie_titles, mask_token=None),\n",
    "          tf.keras.layers.Embedding(len(unique_movie_titles) + 1, embedding_dimension)\n",
    "        ])\n",
    "\n",
    "        # Compute predictions.\n",
    "        self.ratings = tf.keras.Sequential([\n",
    "          # Learn multiple dense layers.\n",
    "          tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "          tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "          # Make rating predictions in the final layer.\n",
    "          tf.keras.layers.Dense(1)\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        user_id, movie_title = inputs\n",
    "\n",
    "        user_embedding = self.user_embeddings(user_id)\n",
    "        movie_embedding = self.movie_embeddings(movie_title)\n",
    "\n",
    "        return self.ratings(tf.concat([user_embedding, movie_embedding], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovielensModel(tfrs.models.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.ranking_model: tf.keras.Model = RankingModel()\n",
    "        self.task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "          loss = tf.keras.losses.MeanSquaredError(),\n",
    "          metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "        )\n",
    "\n",
    "    def call(self, features: Dict[str, tf.Tensor]) -> tf.Tensor:\n",
    "        return self.ranking_model(\n",
    "            (features[\"userId\"], features[\"title\"]))\n",
    "\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "        labels = features.pop(\"rating\")\n",
    "\n",
    "        rating_predictions = self(features)\n",
    "\n",
    "        # The task computes the loss and the metrics.\n",
    "        return self.task(labels=labels, predictions=rating_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MovielensModel()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "10/10 [==============================] - 1s 29ms/step - root_mean_squared_error: 2.3912 - loss: 5.2015 - regularization_loss: 0.0000e+00 - total_loss: 5.2015\n",
      "Epoch 2/3\n",
      "10/10 [==============================] - 0s 8ms/step - root_mean_squared_error: 1.0387 - loss: 1.0768 - regularization_loss: 0.0000e+00 - total_loss: 1.0768\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 0s 8ms/step - root_mean_squared_error: 1.0252 - loss: 1.0493 - regularization_loss: 0.0000e+00 - total_loss: 1.0493\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2317a845ca0>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(cached_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 4ms/step - root_mean_squared_error: 1.0203 - loss: 1.0356 - regularization_loss: 0.0000e+00 - total_loss: 1.0356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'root_mean_squared_error': 1.0202876329421997,\n",
       " 'loss': 1.0118333101272583,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 1.0118333101272583}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) userId with unsupported characters which will be renamed to userid in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as ranking_5_layer_call_fn, ranking_5_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./ml/ranking_mdl\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./ml/ranking_mdl\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save( model, \"./ml/ranking_mdl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ngvn-c0b8lc2"
   },
   "source": [
    "### Rating-specialized model\n",
    "\n",
    "Depending on the weights we assign, the model will encode a different balance of the tasks. Let's start with a model that only considers ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T12:11:58.685325Z",
     "iopub.status.busy": "2021-11-30T12:11:58.683283Z",
     "iopub.status.idle": "2021-11-30T12:11:58.862405Z",
     "shell.execute_reply": "2021-11-30T12:11:58.862819Z"
    },
    "id": "NNfB6rYL0VrS"
   },
   "outputs": [],
   "source": [
    "model = MyModel(rating_weight=1.0, retrieval_weight=0.0)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T12:11:58.868343Z",
     "iopub.status.busy": "2021-11-30T12:11:58.867385Z",
     "iopub.status.idle": "2021-11-30T12:11:58.872371Z",
     "shell.execute_reply": "2021-11-30T12:11:58.872734Z"
    },
    "id": "I6kjfF1j0iZR"
   },
   "outputs": [],
   "source": [
    "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T12:11:58.878250Z",
     "iopub.status.busy": "2021-11-30T12:11:58.877302Z",
     "iopub.status.idle": "2021-11-30T12:12:15.124584Z",
     "shell.execute_reply": "2021-11-30T12:12:15.124102Z"
    },
    "id": "6NWadH1q0c_T"
   },
   "outputs": [],
   "source": [
    "model.fit(cached_train, epochs=5)\n",
    "metrics = model.evaluate(cached_test, return_dict=True)\n",
    "\n",
    "print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
    "print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lENViv04-i0T"
   },
   "source": [
    "The model does OK on predicting ratings (with an RMSE of around 0.98), but performs poorly at predicting which movies will be watched or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yPYd9LtE-4Fm"
   },
   "source": [
    "### Retrieval-specialized model\n",
    "\n",
    "Let's now try a model that focuses on retrieval only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T12:12:15.130042Z",
     "iopub.status.busy": "2021-11-30T12:12:15.129365Z",
     "iopub.status.idle": "2021-11-30T12:12:15.180454Z",
     "shell.execute_reply": "2021-11-30T12:12:15.180841Z"
    },
    "id": "BfnkGd2G--Qt"
   },
   "outputs": [],
   "source": [
    "model = MyModel(rating_weight=0.0, retrieval_weight=1.0)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T12:12:15.186359Z",
     "iopub.status.busy": "2021-11-30T12:12:15.185751Z",
     "iopub.status.idle": "2021-11-30T12:12:26.880167Z",
     "shell.execute_reply": "2021-11-30T12:12:26.879713Z"
    },
    "id": "JCCBdM7U_B11"
   },
   "outputs": [],
   "source": [
    "model.fit(cached_train, epochs=5)\n",
    "metrics = model.evaluate(cached_test, return_dict=True)\n",
    "\n",
    "print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
    "print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YjM7j7eY_jPh"
   },
   "source": [
    "We get the opposite result: a model that does well on retrieval, but poorly on predicting ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hOFwjUus_pLU"
   },
   "source": [
    "### Joint model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T12:12:26.885145Z",
     "iopub.status.busy": "2021-11-30T12:12:26.882803Z",
     "iopub.status.idle": "2021-11-30T12:12:26.933259Z",
     "shell.execute_reply": "2021-11-30T12:12:26.933678Z"
    },
    "id": "7xyDbNMf_t8a"
   },
   "outputs": [],
   "source": [
    "model = MyModel(rating_weight=1.0, retrieval_weight=1.0)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "# model_checkpoint=tf.keras.callbacks.ModelCheckpoint('DeepCrossMultitaskModel{epoch:02d}',save_freq=2,save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T12:12:26.938573Z",
     "iopub.status.busy": "2021-11-30T12:12:26.937999Z",
     "iopub.status.idle": "2021-11-30T12:12:38.227670Z",
     "shell.execute_reply": "2021-11-30T12:12:38.227236Z"
    },
    "id": "2pZmM_ub_uEO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "10/10 [==============================] - 35s 3s/step - root_mean_squared_error: 2.4905 - factorized_top_k/top_1_categorical_accuracy: 0.0649 - factorized_top_k/top_5_categorical_accuracy: 0.0962 - factorized_top_k/top_10_categorical_accuracy: 0.1086 - factorized_top_k/top_50_categorical_accuracy: 0.1466 - factorized_top_k/top_100_categorical_accuracy: 0.1634 - loss: 70372.8920 - regularization_loss: 0.0000e+00 - total_loss: 70372.8920\n",
      "Epoch 2/3\n",
      "10/10 [==============================] - 31s 3s/step - root_mean_squared_error: 1.1774 - factorized_top_k/top_1_categorical_accuracy: 0.0500 - factorized_top_k/top_5_categorical_accuracy: 0.0910 - factorized_top_k/top_10_categorical_accuracy: 0.1080 - factorized_top_k/top_50_categorical_accuracy: 0.1517 - factorized_top_k/top_100_categorical_accuracy: 0.1703 - loss: 70368.5952 - regularization_loss: 0.0000e+00 - total_loss: 70368.5952\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 30s 3s/step - root_mean_squared_error: 1.0483 - factorized_top_k/top_1_categorical_accuracy: 0.0477 - factorized_top_k/top_5_categorical_accuracy: 0.0694 - factorized_top_k/top_10_categorical_accuracy: 0.0958 - factorized_top_k/top_50_categorical_accuracy: 0.1480 - factorized_top_k/top_100_categorical_accuracy: 0.1794 - loss: 70368.3239 - regularization_loss: 0.0000e+00 - total_loss: 70368.3239\n",
      "5/5 [==============================] - 8s 2s/step - root_mean_squared_error: 1.0314 - factorized_top_k/top_1_categorical_accuracy: 0.0441 - factorized_top_k/top_5_categorical_accuracy: 0.0680 - factorized_top_k/top_10_categorical_accuracy: 0.0971 - factorized_top_k/top_50_categorical_accuracy: 0.1529 - factorized_top_k/top_100_categorical_accuracy: 0.1899 - loss: 32589.5469 - regularization_loss: 0.0000e+00 - total_loss: 32589.5469\n",
      "Retrieval top-100 accuracy: 0.190.\n",
      "Ranking RMSE: 1.031.\n"
     ]
    }
   ],
   "source": [
    "model.fit(cached_train, epochs=3)\n",
    "metrics = model.evaluate(cached_test, return_dict=True)\n",
    "\n",
    "print(f\"Retrieval top-100 accuracy: {metrics['factorized_top_k/top_100_categorical_accuracy']:.3f}.\")\n",
    "print(f\"Ranking RMSE: {metrics['root_mean_squared_error']:.3f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ni_rkOsaB3f9"
   },
   "source": [
    "The result is a model that performs roughly as well on both tasks as each specialized model.\n",
    "\n",
    "### Making prediction\n",
    "\n",
    "We can use the trained multitask model to get trained user and movie embeddings, as well as the predicted rating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-30T12:12:38.232658Z",
     "iopub.status.busy": "2021-11-30T12:12:38.232102Z",
     "iopub.status.idle": "2021-11-30T12:12:38.239495Z",
     "shell.execute_reply": "2021-11-30T12:12:38.239870Z"
    },
    "id": "SXXh-PLaH_Vn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating:\n",
      "tf.Tensor([[3.6748526]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "trained_movie_embeddings, trained_user_embeddings, predicted_rating = model({\n",
    "      \"userId\": np.array([671]),\n",
    "      \"title\": np.array([\"Chicago\"])\n",
    "  })\n",
    "print(\"Predicted rating:\")\n",
    "print(predicted_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow_recommenders.metrics.factorized_top_k.FactorizedTopK object at 0x00000231E2F0C0A0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow_recommenders.metrics.factorized_top_k.FactorizedTopK object at 0x00000231E2F0C0A0>, because it is not built.\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) userId with unsupported characters which will be renamed to userid in the SavedModel.\n"
     ]
    },
    {
     "ename": "FailedPreconditionError",
     "evalue": "Failed to serialize the input pipeline graph: ResourceGather is stateful. [Op:DatasetToGraphV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "Input \u001b[1;32mIn [140]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaved_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./ml/ranking_mdl2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\My GitHub\\python\\taghche\\taghenv\\lib\\site-packages\\tensorflow\\python\\saved_model\\save.py:1290\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[0;32m   1288\u001b[0m \u001b[38;5;66;03m# pylint: enable=line-too-long\u001b[39;00m\n\u001b[0;32m   1289\u001b[0m metrics\u001b[38;5;241m.\u001b[39mIncrementWriteApi(_SAVE_V2_LABEL)\n\u001b[1;32m-> 1290\u001b[0m \u001b[43msave_and_return_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1291\u001b[0m metrics\u001b[38;5;241m.\u001b[39mIncrementWrite(write_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mE:\\My GitHub\\python\\taghche\\taghenv\\lib\\site-packages\\tensorflow\\python\\saved_model\\save.py:1325\u001b[0m, in \u001b[0;36msave_and_return_nodes\u001b[1;34m(obj, export_dir, signatures, options, experimental_skip_checkpoint)\u001b[0m\n\u001b[0;32m   1321\u001b[0m saved_model \u001b[38;5;241m=\u001b[39m saved_model_pb2\u001b[38;5;241m.\u001b[39mSavedModel()\n\u001b[0;32m   1322\u001b[0m meta_graph_def \u001b[38;5;241m=\u001b[39m saved_model\u001b[38;5;241m.\u001b[39mmeta_graphs\u001b[38;5;241m.\u001b[39madd()\n\u001b[0;32m   1324\u001b[0m _, exported_graph, object_saver, asset_info, saved_nodes, node_paths \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 1325\u001b[0m     \u001b[43m_build_meta_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_graph_def\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1326\u001b[0m saved_model\u001b[38;5;241m.\u001b[39msaved_model_schema_version \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1327\u001b[0m     constants\u001b[38;5;241m.\u001b[39mSAVED_MODEL_SCHEMA_VERSION)\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;66;03m# Write the checkpoint, copy assets into the assets directory, and write out\u001b[39;00m\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;66;03m# the SavedModel proto itself.\u001b[39;00m\n",
      "File \u001b[1;32mE:\\My GitHub\\python\\taghche\\taghenv\\lib\\site-packages\\tensorflow\\python\\saved_model\\save.py:1491\u001b[0m, in \u001b[0;36m_build_meta_graph\u001b[1;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[0;32m   1466\u001b[0m \u001b[38;5;124;03m\"\"\"Creates a MetaGraph under a save context.\u001b[39;00m\n\u001b[0;32m   1467\u001b[0m \n\u001b[0;32m   1468\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1487\u001b[0m \u001b[38;5;124;03m  asset_info: `_AssetInfo` tuple containing external assets in the `obj`.\u001b[39;00m\n\u001b[0;32m   1488\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1490\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m save_context\u001b[38;5;241m.\u001b[39msave_context(options):\n\u001b[1;32m-> 1491\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_build_meta_graph_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_graph_def\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\My GitHub\\python\\taghche\\taghenv\\lib\\site-packages\\tensorflow\\python\\saved_model\\save.py:1443\u001b[0m, in \u001b[0;36m_build_meta_graph_impl\u001b[1;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[0;32m   1440\u001b[0m augmented_graph_view\u001b[38;5;241m.\u001b[39mset_signature(signature_map, wrapped_functions)\n\u001b[0;32m   1442\u001b[0m \u001b[38;5;66;03m# Use _SaveableView to provide a frozen listing of properties and functions.\u001b[39;00m\n\u001b[1;32m-> 1443\u001b[0m saveable_view \u001b[38;5;241m=\u001b[39m \u001b[43m_SaveableView\u001b[49m\u001b[43m(\u001b[49m\u001b[43maugmented_graph_view\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1444\u001b[0m object_saver \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mTrackableSaver(augmented_graph_view)\n\u001b[0;32m   1445\u001b[0m asset_info, exported_graph \u001b[38;5;241m=\u001b[39m _fill_meta_graph_def(\n\u001b[0;32m   1446\u001b[0m     meta_graph_def, saveable_view, signatures,\n\u001b[0;32m   1447\u001b[0m     options\u001b[38;5;241m.\u001b[39mnamespace_whitelist, options\u001b[38;5;241m.\u001b[39mexperimental_custom_gradients)\n",
      "File \u001b[1;32mE:\\My GitHub\\python\\taghche\\taghenv\\lib\\site-packages\\tensorflow\\python\\saved_model\\save.py:229\u001b[0m, in \u001b[0;36m_SaveableView.__init__\u001b[1;34m(self, augmented_graph_view, options)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maugmented_graph_view \u001b[38;5;241m=\u001b[39m augmented_graph_view\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options \u001b[38;5;241m=\u001b[39m options\n\u001b[0;32m    227\u001b[0m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trackable_objects, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_paths, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_ids,\n\u001b[0;32m    228\u001b[0m  \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slot_variables, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobject_names) \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 229\u001b[0m      \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugmented_graph_view\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobjects_ids_and_slot_variables_and_paths\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    231\u001b[0m untraced_functions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maugmented_graph_view\u001b[38;5;241m.\u001b[39muntraced_functions\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m untraced_functions:\n",
      "File \u001b[1;32mE:\\My GitHub\\python\\taghche\\taghenv\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\graph_view.py:544\u001b[0m, in \u001b[0;36mObjectGraphView.objects_ids_and_slot_variables_and_paths\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobjects_ids_and_slot_variables_and_paths\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    533\u001b[0m   \u001b[38;5;124;03m\"\"\"Traverse the object graph and list all accessible objects.\u001b[39;00m\n\u001b[0;32m    534\u001b[0m \n\u001b[0;32m    535\u001b[0m \u001b[38;5;124;03m  Looks for `Trackable` objects which are dependencies of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;124;03m                object -> node id, slot variables, object_names)\u001b[39;00m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 544\u001b[0m   trackable_objects, node_paths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_breadth_first_traversal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    545\u001b[0m   object_names \u001b[38;5;241m=\u001b[39m object_identity\u001b[38;5;241m.\u001b[39mObjectIdentityDictionary()\n\u001b[0;32m    546\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m obj, path \u001b[38;5;129;01min\u001b[39;00m node_paths\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32mE:\\My GitHub\\python\\taghche\\taghenv\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\graph_view.py:255\u001b[0m, in \u001b[0;36mObjectGraphView._breadth_first_traversal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    253\u001b[0m current_trackable \u001b[38;5;241m=\u001b[39m to_visit\u001b[38;5;241m.\u001b[39mpopleft()\n\u001b[0;32m    254\u001b[0m bfs_sorted\u001b[38;5;241m.\u001b[39mappend(current_trackable)\n\u001b[1;32m--> 255\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, dependency \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlist_children(current_trackable):\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dependency \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m node_paths:\n\u001b[0;32m    257\u001b[0m     node_paths[dependency] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    258\u001b[0m         node_paths[current_trackable] \u001b[38;5;241m+\u001b[39m (\n\u001b[0;32m    259\u001b[0m             base\u001b[38;5;241m.\u001b[39mTrackableReference(name, dependency),))\n",
      "File \u001b[1;32mE:\\My GitHub\\python\\taghche\\taghenv\\lib\\site-packages\\tensorflow\\python\\saved_model\\save.py:143\u001b[0m, in \u001b[0;36m_AugmentedGraphView.list_children\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_children_cache:\n\u001b[0;32m    141\u001b[0m   children \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_children_cache[obj] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 143\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_AugmentedGraphView\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_children\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[43m      \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m      \u001b[49m\u001b[43msave_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSaveType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSAVEDMODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_serialization_cache\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(child, defun\u001b[38;5;241m.\u001b[39mConcreteFunction):\n\u001b[0;32m    148\u001b[0m       child \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_uncache_variable_captures(child)\n",
      "File \u001b[1;32mE:\\My GitHub\\python\\taghche\\taghenv\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\graph_view.py:203\u001b[0m, in \u001b[0;36mObjectGraphView.list_children\u001b[1;34m(self, obj, save_type, **kwargs)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    201\u001b[0m obj\u001b[38;5;241m.\u001b[39m_maybe_initialize_trackable()\n\u001b[0;32m    202\u001b[0m children \u001b[38;5;241m=\u001b[39m [base\u001b[38;5;241m.\u001b[39mTrackableReference(name, ref) \u001b[38;5;28;01mfor\u001b[39;00m name, ref\n\u001b[1;32m--> 203\u001b[0m             \u001b[38;5;129;01min\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_trackable_children\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[0;32m    204\u001b[0m \u001b[38;5;66;03m# pylint: enable=protected-access\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \n\u001b[0;32m    206\u001b[0m \u001b[38;5;66;03m# GraphView objects may define children of the root object that are not\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;66;03m# actually attached, e.g. a Checkpoint object's save_counter.\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attached_dependencies:\n",
      "File \u001b[1;32mE:\\My GitHub\\python\\taghche\\taghenv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:345\u001b[0m, in \u001b[0;36mDatasetV2._trackable_children\u001b[1;34m(self, save_type, **kwargs)\u001b[0m\n\u001b[0;32m    343\u001b[0m   resource \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trace_variant_creation()()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    344\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m resource\n\u001b[1;32m--> 345\u001b[0m \u001b[43m_creator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_concrete_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Trigger asset tracking\u001b[39;00m\n\u001b[0;32m    347\u001b[0m children \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(DatasetV2, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_trackable_children(save_type, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    348\u001b[0m children[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_variant_tracker\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _VariantTracker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor,\n\u001b[0;32m    349\u001b[0m                                                _creator)\n",
      "File \u001b[1;32mE:\\My GitHub\\python\\taghche\\taghenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:1239\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1238\u001b[0m   \u001b[38;5;66;03m# Implements GenericFunction.get_concrete_function.\u001b[39;00m\n\u001b[1;32m-> 1239\u001b[0m   concrete \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1240\u001b[0m   concrete\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1241\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete\n",
      "File \u001b[1;32mE:\\My GitHub\\python\\taghche\\taghenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:1219\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1217\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1218\u001b[0m     initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 1219\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1220\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[0;32m   1222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m   1223\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m   1224\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n",
      "File \u001b[1;32mE:\\My GitHub\\python\\taghche\\taghenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:785\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    782\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph \u001b[38;5;241m=\u001b[39m lifted_initializer_graph\n\u001b[0;32m    783\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph_deleter \u001b[38;5;241m=\u001b[39m FunctionDeleter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lifted_initializer_graph)\n\u001b[0;32m    784\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_stateful_fn \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 785\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateful_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_internal_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    786\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    788\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[0;32m    789\u001b[0m   \u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mE:\\My GitHub\\python\\taghche\\taghenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2480\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2478\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2479\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m-> 2480\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32mE:\\My GitHub\\python\\taghche\\taghenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2711\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2708\u001b[0m   cache_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mgeneralize(cache_key)\n\u001b[0;32m   2709\u001b[0m   (args, kwargs) \u001b[38;5;241m=\u001b[39m cache_key\u001b[38;5;241m.\u001b[39m_placeholder_value()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 2711\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2712\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39madd(cache_key, cache_key_deletion_observer,\n\u001b[0;32m   2713\u001b[0m                          graph_function)\n\u001b[0;32m   2715\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[1;32mE:\\My GitHub\\python\\taghche\\taghenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2627\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2622\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   2623\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   2624\u001b[0m ]\n\u001b[0;32m   2625\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[0;32m   2626\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 2627\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2628\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2629\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2630\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2631\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2632\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2635\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   2637\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[0;32m   2638\u001b[0m     spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[0;32m   2639\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   2640\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   2641\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   2642\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   2643\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   2644\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32mE:\\My GitHub\\python\\taghche\\taghenv\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1141\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1138\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1139\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1141\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[0;32m   1146\u001b[0m     convert, func_outputs, expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mE:\\My GitHub\\python\\taghche\\taghenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:677\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    674\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    675\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[0;32m    676\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[1;32m--> 677\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    678\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mE:\\My GitHub\\python\\taghche\\taghenv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:343\u001b[0m, in \u001b[0;36mDatasetV2._trackable_children.<locals>._creator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;129m@def_function\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(input_signature\u001b[38;5;241m=\u001b[39m[], autograph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_creator\u001b[39m():\n\u001b[1;32m--> 343\u001b[0m   resource \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_trace_variant_creation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    344\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m resource\n",
      "File \u001b[1;32mE:\\My GitHub\\python\\taghche\\taghenv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:370\u001b[0m, in \u001b[0;36mDatasetV2._trace_variant_creation\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    363\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    364\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConstructing a tf.function that reproduces a given dataset is only \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupported for datasets created eagerly. Please file a feature \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest if this is important to you.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39meager_mode(), ops\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCPU\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    368\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    369\u001b[0m   graph_def \u001b[38;5;241m=\u001b[39m graph_pb2\u001b[38;5;241m.\u001b[39mGraphDef()\u001b[38;5;241m.\u001b[39mFromString(\n\u001b[1;32m--> 370\u001b[0m       \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_as_serialized_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexternal_state_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions_lib\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mExternalStatePolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFAIL\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m    372\u001b[0m output_node_names \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m graph_def\u001b[38;5;241m.\u001b[39mnode:\n",
      "File \u001b[1;32mE:\\My GitHub\\python\\taghche\\taghenv\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:561\u001b[0m, in \u001b[0;36mdeprecated_args.<locals>.deprecated_wrapper.<locals>.new_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m         _PRINTED_WARNING[(func, arg_name)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    554\u001b[0m       logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    555\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrom \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: calling \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is deprecated and will \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    556\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbe removed \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInstructions for updating:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    559\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min a future version\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m date),\n\u001b[0;32m    560\u001b[0m           instructions)\n\u001b[1;32m--> 561\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\My GitHub\\python\\taghche\\taghenv\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:290\u001b[0m, in \u001b[0;36mDatasetV2._as_serialized_graph\u001b[1;34m(self, allow_stateful, strip_device_assignment, external_state_policy)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m external_state_policy:\n\u001b[0;32m    289\u001b[0m   policy \u001b[38;5;241m=\u001b[39m external_state_policy\u001b[38;5;241m.\u001b[39mvalue\n\u001b[1;32m--> 290\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_to_graph_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variant_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m      \u001b[49m\u001b[43mexternal_state_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m      \u001b[49m\u001b[43mstrip_device_assignment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrip_device_assignment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strip_device_assignment:\n\u001b[0;32m    295\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m gen_dataset_ops\u001b[38;5;241m.\u001b[39mdataset_to_graph(\n\u001b[0;32m    296\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor,\n\u001b[0;32m    297\u001b[0m       allow_stateful\u001b[38;5;241m=\u001b[39mallow_stateful,\n\u001b[0;32m    298\u001b[0m       strip_device_assignment\u001b[38;5;241m=\u001b[39mstrip_device_assignment)\n",
      "File \u001b[1;32mE:\\My GitHub\\python\\taghche\\taghenv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:1331\u001b[0m, in \u001b[0;36mdataset_to_graph_v2\u001b[1;34m(input_dataset, external_state_policy, strip_device_assignment, name)\u001b[0m\n\u001b[0;32m   1329\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1331\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1332\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[0;32m   1333\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mE:\\My GitHub\\python\\taghche\\taghenv\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7164\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7163\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 7164\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Failed to serialize the input pipeline graph: ResourceGather is stateful. [Op:DatasetToGraphV2]"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save( model, \"./ml/ranking_mdl2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies.to_json(orient=\"split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow_recommenders.tasks.retrieval.Retrieval object at 0x00000231EA4A3A90>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow_recommenders.tasks.retrieval.Retrieval object at 0x00000231EA4A3A90>, because it is not built.\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) userId with unsupported characters which will be renamed to userid in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as ranking_6_layer_call_fn, ranking_6_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./ml/multitask_model2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./ml/multitask_model2\\assets\n"
     ]
    }
   ],
   "source": [
    "model.retrieval_task = tfrs.tasks.Retrieval()  # Removes the metrics.\n",
    "model.compile()\n",
    "tf.saved_model.save(model, \"./ml/multitask_model2\")\n",
    "# tf.keras.models.save_model( model, \"./ml/ranking_model\", overwrite=True)\n",
    "# model.save(\"./ml/multit_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) userId with unsupported characters which will be renamed to userid in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as ranking_5_layer_call_fn, ranking_5_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./ml/ranking_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./ml/ranking_model\\assets\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Unable to serialize b'\"\\'71 (2014)\"' to JSON. Unrecognized type <class 'bytes'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [121]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./ml/ranking_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\My GitHub\\python\\taghche\\taghenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\users\\nzd.digital\\appdata\\local\\programs\\python\\python38\\lib\\json\\encoder.py:199\u001b[0m, in \u001b[0;36mJSONEncoder.encode\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m encode_basestring(o)\n\u001b[0;32m    196\u001b[0m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[1;32m--> 199\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_one_shot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m    201\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(chunks)\n",
      "File \u001b[1;32mc:\\users\\nzd.digital\\appdata\\local\\programs\\python\\python38\\lib\\json\\encoder.py:257\u001b[0m, in \u001b[0;36mJSONEncoder.iterencode\u001b[1;34m(self, o, _one_shot)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    253\u001b[0m     _iterencode \u001b[38;5;241m=\u001b[39m _make_iterencode(\n\u001b[0;32m    254\u001b[0m         markers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault, _encoder, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindent, floatstr,\n\u001b[0;32m    255\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_separator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msort_keys,\n\u001b[0;32m    256\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskipkeys, _one_shot)\n\u001b[1;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_iterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: Unable to serialize b'\"\\'71 (2014)\"' to JSON. Unrecognized type <class 'bytes'>."
     ]
    }
   ],
   "source": [
    "model.save(\"./ml/ranking_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings:\n",
      "M*A*S*H (1970): [[3.6040702]]\n",
      "Dances with Wolves (1990): [[3.6040702]]\n",
      "Speed (1994): [[3.6040702]]\n"
     ]
    }
   ],
   "source": [
    "test_ratings = {}\n",
    "test_movie_titles = [\"M*A*S*H (1970)\", \"Dances with Wolves (1990)\", \"Speed (1994)\"]\n",
    "for movie_title in test_movie_titles:\n",
    "    test_ratings[movie_title] = model({\n",
    "      \"userId\": np.array([42]),\n",
    "      \"title\": np.array([movie_title])\n",
    "  })\n",
    "\n",
    "print(\"Ratings:\")\n",
    "for title, score in sorted(test_ratings.items(), key=lambda x: x[1], reverse=True):\n",
    "  print(f\"{title}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not find matching concrete function to call loaded from the SavedModel. Got:\n  Positional arguments (2 total):\n    * {'features/title': <tf.Tensor 'features:0' shape=(1,) dtype=string>,\n 'features/userId': <tf.Tensor 'features_1:0' shape=(1,) dtype=int32>}\n    * False\n  Keyword arguments: {}\n\n Expected these arguments to match one of the following 4 option(s):\n\nOption 1:\n  Positional arguments (2 total):\n    * {'title': TensorSpec(shape=(None,), dtype=tf.string, name='title'),\n 'userId': TensorSpec(shape=(None,), dtype=tf.int64, name='userId')}\n    * False\n  Keyword arguments: {}\n\nOption 2:\n  Positional arguments (2 total):\n    * {'title': TensorSpec(shape=(None,), dtype=tf.string, name='features/title'),\n 'userId': TensorSpec(shape=(None,), dtype=tf.int64, name='features/userId')}\n    * False\n  Keyword arguments: {}\n\nOption 3:\n  Positional arguments (2 total):\n    * {'title': TensorSpec(shape=(None,), dtype=tf.string, name='features/title'),\n 'userId': TensorSpec(shape=(None,), dtype=tf.int64, name='features/userId')}\n    * True\n  Keyword arguments: {}\n\nOption 4:\n  Positional arguments (2 total):\n    * {'title': TensorSpec(shape=(None,), dtype=tf.string, name='title'),\n 'userId': TensorSpec(shape=(None,), dtype=tf.int64, name='userId')}\n    * True\n  Keyword arguments: {}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [145]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m new_model \u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39msaved_model\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./ml/multitask_model2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#double check: expect to produce the same thing as model(dict(test_df.head(3)))\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[43mnew_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfeatures/title\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mKill\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfeatures/userId\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m610\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\My GitHub\\python\\taghche\\taghenv\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:686\u001b[0m, in \u001b[0;36m_call_attribute\u001b[1;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[0;32m    685\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_attribute\u001b[39m(instance, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 686\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minstance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\My GitHub\\python\\taghche\\taghenv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mE:\\My GitHub\\python\\taghche\\taghenv\\lib\\site-packages\\tensorflow\\python\\saved_model\\function_deserialization.py:286\u001b[0m, in \u001b[0;36mrecreate_function.<locals>.restored_function_body\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    282\u001b[0m   positional, keyword \u001b[38;5;241m=\u001b[39m concrete_function\u001b[38;5;241m.\u001b[39mstructured_input_signature\n\u001b[0;32m    283\u001b[0m   signature_descriptions\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m    284\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOption \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  Keyword arguments: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    285\u001b[0m       \u001b[38;5;241m.\u001b[39mformat(index \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, _pretty_format_positional(positional), keyword))\n\u001b[1;32m--> 286\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find matching concrete function to call loaded from the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSavedModel. Got:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_pretty_format_positional(args)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  Keyword \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marguments: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Expected these arguments to match one of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfollowing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(saved_function\u001b[38;5;241m.\u001b[39mconcrete_functions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m option(s):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(\u001b[38;5;28mchr\u001b[39m(\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mchr\u001b[39m(\u001b[38;5;241m10\u001b[39m))\u001b[38;5;241m.\u001b[39mjoin(signature_descriptions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Could not find matching concrete function to call loaded from the SavedModel. Got:\n  Positional arguments (2 total):\n    * {'features/title': <tf.Tensor 'features:0' shape=(1,) dtype=string>,\n 'features/userId': <tf.Tensor 'features_1:0' shape=(1,) dtype=int32>}\n    * False\n  Keyword arguments: {}\n\n Expected these arguments to match one of the following 4 option(s):\n\nOption 1:\n  Positional arguments (2 total):\n    * {'title': TensorSpec(shape=(None,), dtype=tf.string, name='title'),\n 'userId': TensorSpec(shape=(None,), dtype=tf.int64, name='userId')}\n    * False\n  Keyword arguments: {}\n\nOption 2:\n  Positional arguments (2 total):\n    * {'title': TensorSpec(shape=(None,), dtype=tf.string, name='features/title'),\n 'userId': TensorSpec(shape=(None,), dtype=tf.int64, name='features/userId')}\n    * False\n  Keyword arguments: {}\n\nOption 3:\n  Positional arguments (2 total):\n    * {'title': TensorSpec(shape=(None,), dtype=tf.string, name='features/title'),\n 'userId': TensorSpec(shape=(None,), dtype=tf.int64, name='features/userId')}\n    * True\n  Keyword arguments: {}\n\nOption 4:\n  Positional arguments (2 total):\n    * {'title': TensorSpec(shape=(None,), dtype=tf.string, name='title'),\n 'userId': TensorSpec(shape=(None,), dtype=tf.int64, name='userId')}\n    * True\n  Keyword arguments: {}"
     ]
    }
   ],
   "source": [
    "# #!mkdir -p saved_model\n",
    "# filepath = \"./ml/multit_model_weight.h5\"\n",
    "\n",
    "# model.save_weights(filepath=filepath)\n",
    "# # newly instantiate & compile a model\n",
    "# # new_model = MyModel(rating_weight=1.0, retrieval_weight=1.0)\n",
    "# # new_model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "\n",
    "# # load the weights back to the new model\n",
    "# from keras.models import load_model\n",
    "\n",
    "\n",
    "new_model =tf.saved_model.load(\"./ml/multitask_model2\")\n",
    "\n",
    "#double check: expect to produce the same thing as model(dict(test_df.head(3)))\n",
    "new_model({\n",
    "    \"features/title\": np.array([\"Kill\"]),\n",
    "    \"features/userId\": np.array([610])  \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model that takes in raw query features, and\n",
    "index = tfrs.layers.factorized_top_k.BruteForce(model.user_model)\n",
    "# recommends books out of the entire books dataset.\n",
    "index.index_from_dataset(\n",
    "  tf.data.Dataset.zip((movies.batch(100), movies.batch(100).map(model.movie_model)))\n",
    ")\n",
    "\n",
    "# Get recommendations.\n",
    "_, titles = index(tf.constant([671]))\n",
    "print(f\"Recommendations for user 671: {titles[0, :5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FADp0pUWINTD"
   },
   "source": [
    "While the results here do not show a clear accuracy benefit from a joint model in this case, multi-task learning is in general an extremely useful tool. We can expect better results when we can transfer knowledge from a data-abundant task (such as clicks) to a closely related data-sparse task (such as purchases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.saved_model.save(index, path)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "multitask.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
